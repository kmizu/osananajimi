"""
å°èª¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç”¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
"""

import re
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime


@dataclass
class ChapterInfo:
    """ç« æƒ…å ±"""
    number: int
    title: str
    file_path: Path
    char_count: int
    created_at: Optional[datetime] = None
    modified_at: Optional[datetime] = None


@dataclass
class NovelStats:
    """å°èª¬çµ±è¨ˆæƒ…å ±"""
    total_chapters: int
    total_characters: int
    average_chars_per_chapter: int
    chapters: List[ChapterInfo]


def count_japanese_characters(text: str) -> int:
    """æ—¥æœ¬èªæ–‡å­—æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆï¼ˆæ”¹è¡Œãƒ»ç©ºç™½é™¤ãï¼‰"""
    # Markdownãƒ˜ãƒƒãƒ€ãƒ¼ã‚’é™¤å»
    text = re.sub(r'^#.*$', '', text, flags=re.MULTILINE)
    
    # æ”¹è¡Œãƒ»ç©ºç™½ãƒ»è¨˜å·ã‚’é™¤å»ã—ã¦æ—¥æœ¬èªæ–‡å­—ã®ã¿ã‚«ã‚¦ãƒ³ãƒˆ
    japanese_chars = re.findall(r'[ã-ã‚“ã‚¡-ãƒ³ãƒ¼ä¸€-é¾¯]', text)
    return len(japanese_chars)


def parse_chapter_title(content: str) -> Optional[str]:
    """Markdownã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰ç« ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡º"""
    match = re.search(r'^#\s+(.+?)$', content, re.MULTILINE)
    if match:
        return match.group(1).strip()
    return None


def analyze_chapter(file_path: Path) -> Optional[ChapterInfo]:
    """ç« ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ"""
    try:
        content = file_path.read_text(encoding='utf-8')
        
        # ç« ç•ªå·ã‚’ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æŠ½å‡º
        match = re.search(r'chapter(\d+)', file_path.stem)
        if not match:
            return None
        
        chapter_num = int(match.group(1))
        title = parse_chapter_title(content) or f"ç¬¬{chapter_num}è©±"
        char_count = count_japanese_characters(content)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ™‚åˆ»æƒ…å ±
        stat = file_path.stat()
        created_at = datetime.fromtimestamp(stat.st_ctime)
        modified_at = datetime.fromtimestamp(stat.st_mtime)
        
        return ChapterInfo(
            number=chapter_num,
            title=title,
            file_path=file_path,
            char_count=char_count,
            created_at=created_at,
            modified_at=modified_at
        )
    except Exception:
        return None


def analyze_novel_project(project_root: Path) -> NovelStats:
    """å°èª¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã‚’è§£æ"""
    docs_dir = project_root / "docs"
    if not docs_dir.exists():
        return NovelStats(0, 0, 0, [])
    
    chapters = []
    
    # å…¨ã¦ã®ç« ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    for md_file in docs_dir.rglob("chapter*.md"):
        chapter_info = analyze_chapter(md_file)
        if chapter_info:
            chapters.append(chapter_info)
    
    # ç« ç•ªå·ã§ã‚½ãƒ¼ãƒˆ
    chapters.sort(key=lambda x: x.number)
    
    # çµ±è¨ˆè¨ˆç®—
    total_chapters = len(chapters)
    total_characters = sum(ch.char_count for ch in chapters)
    avg_chars = total_characters // total_chapters if total_chapters > 0 else 0
    
    return NovelStats(
        total_chapters=total_chapters,
        total_characters=total_characters,
        average_chars_per_chapter=avg_chars,
        chapters=chapters
    )


def generate_progress_report(stats: NovelStats) -> str:
    """é€²æ—ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
    report = []
    report.append("ğŸ“Š å°èª¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçµ±è¨ˆ")
    report.append("=" * 30)
    report.append(f"ç·ç« æ•°: {stats.total_chapters}è©±")
    report.append(f"ç·æ–‡å­—æ•°: {stats.total_characters:,}æ–‡å­—")
    report.append(f"å¹³å‡æ–‡å­—æ•°: {stats.average_chars_per_chapter:,}æ–‡å­—/è©±")
    report.append("")
    
    if stats.chapters:
        report.append("ğŸ“ ç« åˆ¥è©³ç´°:")
        for chapter in stats.chapters:
            report.append(
                f"  ç¬¬{chapter.number:2d}è©±: {chapter.title:<20} "
                f"({chapter.char_count:4,}æ–‡å­—)"
            )
    
    return "\n".join(report)


def validate_chapter_structure(project_root: Path) -> List[str]:
    """ç« æ§‹æˆã®å¦¥å½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
    issues = []
    stats = analyze_novel_project(project_root)
    
    if not stats.chapters:
        issues.append("âŒ ç« ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return issues
    
    # é€£ç•ªãƒã‚§ãƒƒã‚¯
    numbers = [ch.number for ch in stats.chapters]
    expected = list(range(1, max(numbers) + 1))
    missing = set(expected) - set(numbers)
    
    if missing:
        issues.append(f"âŒ æ¬ ç•ªã®ç« ãŒã‚ã‚Šã¾ã™: {sorted(missing)}")
    
    # æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯
    for chapter in stats.chapters:
        if chapter.char_count < 2000:
            issues.append(f"âš ï¸  ç¬¬{chapter.number}è©±ã®æ–‡å­—æ•°ãŒå°‘ãªã„: {chapter.char_count}æ–‡å­—")
        elif chapter.char_count > 4000:
            issues.append(f"âš ï¸  ç¬¬{chapter.number}è©±ã®æ–‡å­—æ•°ãŒå¤šã„: {chapter.char_count}æ–‡å­—")
    
    if not issues:
        issues.append("âœ… ç« æ§‹æˆã«å•é¡Œã¯ã‚ã‚Šã¾ã›ã‚“")
    
    return issues


def export_for_kakuyomu(project_root: Path, output_path: Path) -> bool:
    """ã‚«ã‚¯ãƒ¨ãƒ æŠ•ç¨¿ç”¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    try:
        stats = analyze_novel_project(project_root)
        
        if not stats.chapters:
            return False
        
        # å…¨ç« ã‚’çµåˆ
        content_parts = []
        content_parts.append("éš£ã®æ‹æ–‡")
        content_parts.append("=" * 20)
        content_parts.append("")
        
        for chapter in stats.chapters:
            chapter_content = chapter.file_path.read_text(encoding='utf-8')
            
            # Markdownãƒ˜ãƒƒãƒ€ãƒ¼ã‚’é™¤å»
            chapter_content = re.sub(r'^#.*$', '', chapter_content, flags=re.MULTILINE)
            chapter_content = chapter_content.strip()
            
            content_parts.append(f"ç¬¬{chapter.number}è©±ã€€{chapter.title}")
            content_parts.append("")
            content_parts.append(chapter_content)
            content_parts.append("")
            content_parts.append("-" * 40)
            content_parts.append("")
        
        # çµ±è¨ˆæƒ…å ±ã‚’è¿½åŠ 
        content_parts.append("")
        content_parts.append(generate_progress_report(stats))
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
        output_content = "\n".join(content_parts)
        output_path.write_text(output_content, encoding='utf-8')
        
        return True
    except Exception:
        return False